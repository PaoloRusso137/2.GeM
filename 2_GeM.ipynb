{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.GeM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/YDVTQIgcOPGGos8yLNtZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaoloRusso137/2.GeM/blob/main/2_GeM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3tXTlaFKWqd",
        "outputId": "268534e7-1122-4072-96d0-b6c0ae1dd9e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PaoloRusso137/2.GeM.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j8SF_xfKhXo",
        "outputId": "14cf3307-7881-480a-cf4d-5e04b5f6757f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path '2.GeM' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"/content/2.GeM\" \"drive/MyDrive\""
      ],
      "metadata": {
        "id": "AIBzGOsMKlVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/MyDrive/pitts30k.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "metadata": {
        "id": "t5uQdX7cKwsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#package installation\n",
        "\n",
        "!pip install faiss_cpu==1.7.1\n",
        "!pip install numpy==1.19.4\n",
        "!pip install Pillow==8.4.0\n",
        "!pip install scikit_learn==1.0.1\n",
        "!pip install torch==1.7.0\n",
        "!pip install torchvision==0.8.1\n",
        "!pip install tqdm==4.48.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jxl52cd1mrL0",
        "outputId": "908c1021-c4f7-4cba-be05-bbc96fc4685e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss_cpu==1.7.1\n",
            "  Downloading faiss_cpu-1.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 11.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.1\n",
            "Collecting numpy==1.19.4\n",
            "  Downloading numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 7.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pillow==8.4.0\n",
            "  Downloading Pillow-8.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 15.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-8.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit_learn==1.0.1\n",
            "  Downloading scikit_learn-1.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (1.19.4)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "Successfully installed scikit-learn-1.0.1\n",
            "Collecting torch==1.7.0\n",
            "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.7 MB 4.2 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.10.0.2)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0\n",
            "Collecting torchvision==0.8.1\n",
            "  Downloading torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 13.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (1.19.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (8.4.0)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (1.7.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (3.10.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "Successfully installed torchvision-0.8.1\n",
            "Collecting tqdm==4.48.2\n",
            "  Downloading tqdm-4.48.2-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 5.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tqdm-4.48.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FIRST TRAINING:** The cd command is set to let the RUNS folder (which contains the log and the best_model) inside the GOOGLE DRIVE where the train was run\n",
        "\n",
        "Since the train have been already performed, the best_model is directly put inside the GitHub"
      ],
      "metadata": {
        "id": "LkSpGH2qOFRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/2.GeM\" "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5y9EckTM7hH",
        "outputId": "60c38e76-33ae-46ad-b164-11806fab3a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/2.GeM\n",
            "/content/drive/MyDrive/2.GeM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAIN**"
      ],
      "metadata": {
        "id": "vhsOG5NjPCT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"train.py\" --datasets_folder \"/content/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxyQUsk9Os_L",
        "outputId": "0ca37248-e4cd-4aba-9759-98e208bb613f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-01-15 16:13:12   Arguments: Namespace(cache_refresh_rate=1000, datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_workers=8, output_folder='runs/default/2022-01-15_16-13-12', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, val_positive_dist_threshold=25)\n",
            "2022-01-15 16:13:12   The outputs are being saved in runs/default/2022-01-15_16-13-12\n",
            "2022-01-15 16:13:13   Using 1 GPUs and 2 CPUs\n",
            "2022-01-15 16:13:13   Loading dataset Pitts30k from folder /content/\n",
            "2022-01-15 16:13:13   \n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 34, in <module>\n",
            "    triplets_ds = datasets_ws.TripletsDataset(args, args.datasets_folder, \"pitts30k\", \"train\", args.negs_num_per_query)\n",
            "  File \"/content/drive/MyDrive/2.GeM/datasets_ws.py\", line 106, in __init__\n",
            "    super().__init__(args, datasets_folder, dataset_name, split)\n",
            "  File \"/content/drive/MyDrive/2.GeM/datasets_ws.py\", line 60, in __init__\n",
            "    if not os.path.exists(self.dataset_folder): raise FileNotFoundError(f\"Folder {self.dataset_folder} does not exist\")\n",
            "FileNotFoundError: Folder /content/pitts30k/images/train does not exist\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TEST** \n",
        "Please NOTE that the test here proposed is set fro the best_model.pth downloaded from the GitHub."
      ],
      "metadata": {
        "id": "sVtMpXP7PIGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To have the test done over the best_model just created from a training above; THE DIRECTORY IN THE FILE **REAL_TEST.PY** AL LINE 44 HAS TO BE CHANGED WITH THE DIRECTORY OF THE NEW CALCULATED BEST_MODEL.PTH INSIDE THE RUNS FOLDER"
      ],
      "metadata": {
        "id": "Aty4WkMWQRoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/MyDrive/2.Gem/best_model.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "metadata": {
        "id": "jQ__-NSwT8fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"real_test.py\" --datasets_folder \"/content/\""
      ],
      "metadata": {
        "id": "99CUh8VLQH4n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}